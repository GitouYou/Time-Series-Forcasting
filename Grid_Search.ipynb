{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid_Search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnJ0od0ZvJFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##### CNN Grid Search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_COdTDGvQs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue6xBea9MyOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgcdp1sGvT-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"Work_with_Ambuj.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPCOfsm_8wmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrgyJeOdx5JS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.set_index('Date', inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3MWMAjftWG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.index = pd.to_datetime(df.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_Udy6svtWZd",
        "colab_type": "code",
        "outputId": "05a038b0-268a-49cf-dbec-8ae83852933e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df2  = df.as_matrix()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiP34t0itWln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = (df2-df2.min())/(df2.max()-df2.min())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWhHMKrNuLHI",
        "colab_type": "code",
        "outputId": "f230d5d7-977c-491c-fbb0-ed963d094632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from numpy import array\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM52G9HGuLUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkLzpGU1uLSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW0w6Bn7uLPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "# find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "# check if we are beyond the dataset\n",
        "        if end_ix > len(sequences):\n",
        "            break\n",
        "# gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg8M_O5ZuLMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 2\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqBNWxm4NETm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = X[:1306]\n",
        "y_train = y[:1306]\n",
        "x_test = X[1306:]\n",
        "y_test = y[1306:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6kofEZKt8UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = x_train.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tofy_uovt8Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLjp1lkSit7_",
        "colab_type": "code",
        "outputId": "247c6be7-d413-48f5-bca3-2ec64597773c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(neurons=1, hidden_layers = 1):\n",
        "  \n",
        "\t# create model\n",
        "  for i in range(hidden_layers):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(n_steps,n_features)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(neurons, activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [5]\n",
        "epochs = [5,10]\n",
        "hidden_layers = [1,2]\n",
        "neurons = [2,4]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs, hidden_layers = hidden_layers, neurons = neurons)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Best: 0.002297 using {'batch_size': 5, 'epochs': 10, 'hidden_layers': 2, 'neurons': 2}\n",
            "0.001531 (0.002167) with: {'batch_size': 5, 'epochs': 5, 'hidden_layers': 1, 'neurons': 2}\n",
            "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 5, 'hidden_layers': 1, 'neurons': 4}\n",
            "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 5, 'hidden_layers': 2, 'neurons': 2}\n",
            "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 5, 'hidden_layers': 2, 'neurons': 4}\n",
            "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 10, 'hidden_layers': 1, 'neurons': 2}\n",
            "0.000000 (0.000000) with: {'batch_size': 5, 'epochs': 10, 'hidden_layers': 1, 'neurons': 4}\n",
            "0.002297 (0.001877) with: {'batch_size': 5, 'epochs': 10, 'hidden_layers': 2, 'neurons': 2}\n",
            "0.002297 (0.001876) with: {'batch_size': 5, 'epochs': 10, 'hidden_layers': 2, 'neurons': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC_wSOj0x6Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJDRQUDy06Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLlmUnlW06tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5qcHh3rDLdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oXCkJzB06pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Multi_Headed_CNN\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnpUl0KODt6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "from sklearn.metrics import r2_score\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67oAj-Usx_eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sequenc(sequences, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequences)):\n",
        "# find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "# check if we are beyond the dataset\n",
        "        if end_ix > len(sequences):\n",
        "            break\n",
        "# gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnOzuUzGN2uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequenc(dataset, n_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxGycqq7OFYU",
        "colab_type": "code",
        "outputId": "d9b07646-4dea-4288-d27a-04f329e93beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(X.shape, y.shape)\n",
        "x_train = X[:1306]\n",
        "y_train = y[:1306]\n",
        "x_test = X[1306:]\n",
        "y_test = y[1306:]\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1563, 3, 20) (1563,)\n",
            "(1306, 3, 20)\n",
            "(1306,)\n",
            "(257, 3, 20)\n",
            "(257,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpTIY6eQ3yfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bulOk8ONQpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# separate input data\n",
        "X1 = x_train[:, :, 0].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X2 = x_train[:, :, 1].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X3 = x_train[:, :, 2].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X4 = x_train[:, :, 3].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X5 = x_train[:, :, 4].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X6 = x_train[:, :, 5].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X7 = x_train[:, :, 6].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "\n",
        "X8 = x_train[:, :, 7].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X9 = x_train[:, :, 8].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X10 = x_train[:, :, 9].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X11 = x_train[:, :, 10].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X12 = x_train[:, :, 11].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X13 = x_train[:, :, 12].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X14 = x_train[:, :, 13].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X15 = x_train[:, :, 14].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X16 = x_train[:, :, 15].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X17 = x_train[:, :, 16].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X18 = x_train[:, :, 17].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "\n",
        "X19 = x_train[:, :, 18].reshape(x_train.shape[0], x_train.shape[1], n_features)\n",
        "X20 = x_train[:, :, 19].reshape(x_train.shape[0], x_train.shape[1], n_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W10fat9ZiJgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AX1 = x_test[:, :, 0].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX2 = x_test[:, :, 1].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX3 = x_test[:, :, 2].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX4 = x_test[:, :, 3].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX5 = x_test[:, :, 4].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX6 = x_test[:, :, 5].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX7 = x_test[:, :, 6].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "\n",
        "AX8 = x_test[:, :, 7].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX9 = x_test[:, :, 8].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX10 = x_test[:, :, 9].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX11 = x_test[:, :, 10].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX12 = x_test[:, :, 11].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX13 = x_test[:, :, 12].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX14 = x_test[:, :, 13].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "\n",
        "AX15 = x_test[:, :, 14].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX16 = x_test[:, :, 15].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX17 = x_test[:, :, 16].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX18 = x_test[:, :, 17].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX19 = x_test[:, :, 18].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "AX20 = x_test[:, :, 19].reshape(x_test.shape[0], x_test.shape[1], n_features)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xEUUketyWMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "#opt = SGD(lr = 0.01, momentum = 0.9, decay = 0.01)\n",
        "\n",
        "opt = Adam(lr=0.001, beta_1=0.99, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUDUgt19yY_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(neurons=1, hidden_layers = 1):\n",
        "  \n",
        "\t# create model\n",
        "  for i in range(hidden_layers):\n",
        "    \n",
        "    visible1 = Input(shape=(n_steps, n_features))\n",
        "    cnn1 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible1)\n",
        "    cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
        "    cnn1 = Flatten()(cnn1)\n",
        "\n",
        "    visible2 = Input(shape=(n_steps, n_features))\n",
        "    cnn2 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible2)\n",
        "    cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
        "    cnn2 = Flatten()(cnn2)\n",
        "\n",
        "    visible3 = Input(shape=(n_steps, n_features))\n",
        "    cnn3 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible3)\n",
        "    cnn3 = MaxPooling1D(pool_size=2)(cnn3)\n",
        "    cnn3 = Flatten()(cnn3)\n",
        "\n",
        "    visible4 = Input(shape=(n_steps, n_features))\n",
        "    cnn4 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible4)\n",
        "    cnn4 = MaxPooling1D(pool_size=2)(cnn4)\n",
        "    cnn4 = Flatten()(cnn4)\n",
        "\n",
        "    visible5 = Input(shape=(n_steps, n_features))\n",
        "    cnn5 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible5)\n",
        "    cnn5 = MaxPooling1D(pool_size=2)(cnn5)\n",
        "    cnn5 = Flatten()(cnn5)\n",
        "\n",
        "    visible6 = Input(shape=(n_steps, n_features))\n",
        "    cnn6 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible6)\n",
        "    cnn6 = MaxPooling1D(pool_size=2)(cnn6)\n",
        "    cnn6 = Flatten()(cnn6)\n",
        "\n",
        "    visible7 = Input(shape=(n_steps, n_features))\n",
        "    cnn7 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible7)\n",
        "    cnn7 = MaxPooling1D(pool_size=2)(cnn7)\n",
        "    cnn7 = Flatten()(cnn7)\n",
        "\n",
        "    visible8 = Input(shape=(n_steps, n_features))\n",
        "    cnn8 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible8)\n",
        "    cnn8 = MaxPooling1D(pool_size=2)(cnn8)\n",
        "    cnn8 = Flatten()(cnn8)\n",
        "\n",
        "    visible9 = Input(shape=(n_steps, n_features))\n",
        "    cnn9 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible9)\n",
        "    cnn9 = MaxPooling1D(pool_size=2)(cnn9)\n",
        "    cnn9 = Flatten()(cnn9)\n",
        "\n",
        "    visible10 = Input(shape=(n_steps, n_features))\n",
        "    cnn10 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible10)\n",
        "    cnn10 = MaxPooling1D(pool_size=2)(cnn10)\n",
        "    cnn10 = Flatten()(cnn10)\n",
        "\n",
        "    visible11 = Input(shape=(n_steps, n_features))\n",
        "    cnn11 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible11)\n",
        "    cnn11 = MaxPooling1D(pool_size=2)(cnn11)\n",
        "    cnn11 = Flatten()(cnn11)\n",
        "\n",
        "    visible12 = Input(shape=(n_steps, n_features))\n",
        "    cnn12 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible12)\n",
        "    cnn12 = MaxPooling1D(pool_size=2)(cnn12)\n",
        "    cnn12 = Flatten()(cnn12)\n",
        "\n",
        "    visible13 = Input(shape=(n_steps, n_features))\n",
        "    cnn13 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible13)\n",
        "    cnn13 = MaxPooling1D(pool_size=2)(cnn13)\n",
        "    cnn13 = Flatten()(cnn13)\n",
        "\n",
        "    visible14 = Input(shape=(n_steps, n_features))\n",
        "    cnn14 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible14)\n",
        "    cnn14 = MaxPooling1D(pool_size=2)(cnn14)\n",
        "    cnn14= Flatten()(cnn14)\n",
        "\n",
        "    visible15 = Input(shape=(n_steps, n_features))\n",
        "    cnn15 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible15)\n",
        "    cnn15 = MaxPooling1D(pool_size=2)(cnn15)\n",
        "    cnn15 = Flatten()(cnn15)\n",
        "\n",
        "    visible16 = Input(shape=(n_steps, n_features))\n",
        "    cnn16 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible16)\n",
        "    cnn16 = MaxPooling1D(pool_size=2)(cnn16)\n",
        "    cnn16 = Flatten()(cnn16)\n",
        "\n",
        "    visible17 = Input(shape=(n_steps, n_features))\n",
        "    cnn17 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible17)\n",
        "    cnn17 = MaxPooling1D(pool_size=2)(cnn17)\n",
        "    cnn17 = Flatten()(cnn17)\n",
        "\n",
        "    visible18 = Input(shape=(n_steps, n_features))\n",
        "    cnn18 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible18)\n",
        "    cnn18 = MaxPooling1D(pool_size=2)(cnn18)\n",
        "    cnn18 = Flatten()(cnn18)\n",
        "\n",
        "    visible19 = Input(shape=(n_steps, n_features))\n",
        "    cnn19 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible19)\n",
        "    cnn19 = MaxPooling1D(pool_size=2)(cnn19)\n",
        "    cnn19 = Flatten()(cnn19)\n",
        "\n",
        "    visible20 = Input(shape=(n_steps, n_features))\n",
        "    cnn20 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible20)\n",
        "    cnn20 = MaxPooling1D(pool_size=2)(cnn20)\n",
        "    cnn20 = Flatten()(cnn20)\n",
        "\n",
        "    merge = concatenate([cnn1, cnn2, cnn3, cnn4, cnn5, cnn6, cnn7, cnn8, cnn9, cnn10, cnn11, cnn12,cnn13, cnn14, cnn15, cnn16,cnn17, cnn18, cnn19, cnn20])\n",
        "\n",
        "    merge = concatenate([cnn1, cnn2, cnn3, cnn4, cnn5, cnn6, cnn7, cnn8, cnn9, cnn10, cnn11, cnn12,cnn13, cnn14, cnn15, cnn16,cnn17, cnn18, cnn19, cnn20])\n",
        "    dense = Dense(neurons, activation='relu')(merge)\n",
        "    #dense = Dropout(0.2)(densea)\n",
        "    output = Dense(1)(dense)\n",
        "    model = Model(inputs=[visible1, visible2, visible3, visible4, visible5, visible6, visible7, visible8, visible9, visible10, visible11, visible12, visible13, visible14, visible15, visible16,visible17, visible18, visible19, visible20], outputs=output)\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nmEC1tD05OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = [X1, X2, X3, X4, X5, X6,X7, X8, X9, X10, X11, X12, X13,X14,X15, X16, X17, X18, X19, X20]\n",
        "t_x_t = [AX1, AX2, AX3, AX4, AX5, AX6,AX7, AX8, AX9, AX10, AX11, AX12, AX13,AX14,AX15, AX16, AX17, AX18, AX19, AX20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiYpnyZB04-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34xQbuvHymhb",
        "colab_type": "code",
        "outputId": "a7c363a5-2396-4c7e-f243-5e6ea224dc1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [5]\n",
        "epochs = [5,10]\n",
        "hidden_layers = [1,2]\n",
        "neurons = [2,4]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs, hidden_layers = hidden_layers, neurons = neurons)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "grid_result = grid.fit(x_t, y_train)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-2977cc7bbe8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20, 1306]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acw1a0qz1ALl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}