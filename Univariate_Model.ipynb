{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import load_model\n",
    "from scipy import stats\n",
    "import csv as csv\n",
    "\n",
    "import copy\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "fileName = '1a.csv'\n",
    "modelbestName = \"mlp_1a_best_result_test\"\n",
    "data = read_csv(fileName)\n",
    "dataAvg = [503.62859]\n",
    "dataStd = [100.4557059]\n",
    "\n",
    "nDiff = 1\n",
    "\n",
    "def difference(data):\n",
    "        return [data[i] - data[i - nDiff] for i in range(nDiff, len(data))]\n",
    "\n",
    "def shiftData(data, lag, nOut = 1):\n",
    "        dataOfOneColumn = DataFrame(data)\n",
    "        dataOfOneColumnWithLag = list()\n",
    "        for i in range(lag, 0, -1):\n",
    "                dataOfOneColumnWithLag.append(dataOfOneColumn.shift(i))\n",
    "        for i in range(0, nOut):\n",
    "                dataOfOneColumnWithLag.append(dataOfOneColumn.shift(-i))\n",
    "        dataOfOneColumnWithLag = concat(dataOfOneColumnWithLag, axis = 1)\n",
    "        dataOfOneColumnWithLag.dropna(inplace = True)\n",
    "        return dataOfOneColumnWithLag\n",
    "\n",
    "def prepareDataset(data, lag, numPoints):\n",
    "        trainingData = list()\n",
    "        flag = True\n",
    "        for column in data.columns:\n",
    "              dataOfOneColumnWithLag = np.array(shiftData(data[column], lag))[:numPoints]\n",
    "              if flag == True:\n",
    "                        trainingData = dataOfOneColumnWithLag\n",
    "                        flag = False\n",
    "                        continue\n",
    "              trainingData = np.append(trainingData, dataOfOneColumnWithLag, axis = 0)\n",
    "        return trainingData\n",
    "\n",
    "def train(trainingData, config):\n",
    "        inputShape, numNode, numEpoch, batchSize = config\n",
    "        if nDiff > 0:\n",
    "                trainingData = np.array(difference(trainingData))\n",
    "        trainX, trainY = trainingData[:, :-1], trainingData[:, -1]\n",
    "        #trainX = trainX.reshape((trainX.shape[0], trainX.shape[1], 1))\n",
    "        model = Sequential()\n",
    "        #model.add(LSTM(numNode, activation = 'relu', input_shape = (inputShape, 1)))\n",
    "        model.add(Dense(numNode, activation = 'relu'))\n",
    "        #model.add(Dense(numNode, activation = 'relu'))\n",
    "        #model.add(Dense(numNode, activation = 'relu'))\n",
    "        #model.add(Dense(numNode, activation = 'relu'))\n",
    "        #model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss = 'mse' , optimizer = 'adam')\n",
    "        history = model.fit(trainX, trainY, epochs = numEpoch, batch_size = batchSize, verbose = 0, shuffle = False)\n",
    "        # summarize history for loss\n",
    "        #plt.plot(history.history['loss'])\n",
    "        #plt.plot(history.history['val_loss'])\n",
    "        #plt.title('model loss')\n",
    "        #plt.ylabel('loss')\n",
    "        #plt.xlabel('epoch')\n",
    "        #plt.legend(['train', 'test'], loc='upper left')\n",
    "        #plt.show()\n",
    "        #plt.close()\n",
    "        #plt.savefig(modelName + \"ind\")\n",
    "        #plot_model(model, to_file=modelName+'_.png', show_shapes=True, show_layer_names=True)  \n",
    "        #print(\"training loss:\" , np.mean(np.array(history.history['loss'])))\n",
    "        #print(\"Validation loss:\" , np.mean(np.array(history.history['val_loss'])))\n",
    "        return model,np.mean(np.array(history.history['loss']))\n",
    "\n",
    "def predict(model, testX, inputShape):\n",
    "        testX = np.array(testX).reshape((1, inputShape))\n",
    "        predictions = model.predict(testX, verbose = 0)\n",
    "        return predictions[0]\n",
    "\n",
    "def rsquared(x, y):\n",
    "    \"\"\" Return R^2 where x and y are array-like.\"\"\"\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "    return r_value**2\n",
    "\n",
    "def measureRmse(actual, predicted, dataAvg, dataStd, columnName):\n",
    "        actual = np.array(actual)*dataStd + dataAvg\n",
    "        predicted = np.array(predicted)*dataStd + dataAvg\n",
    "        #print(predicted[0],actual[1])\n",
    "        #np.savetxt(modelName + \"predicted_\" + columnName, predicted)\n",
    "        #np.savetxt(\"actual_\" + columnName, actual)\n",
    "        actualAvg10 = list()\n",
    "        predictedAvg10 = list()\n",
    "        for i in range(0, actual.shape[0], 7):\n",
    "                actualAvg10.append(np.sum(actual[i:i+7]))\n",
    "       \t        predictedAvg10.append(np.sum(predicted[i:i+7]))\n",
    "        #plt.plot(np.array(actualAvg10))\n",
    "        #plt.plot(np.array(predictedAvg10))\n",
    "        #plt.show()\n",
    "        rmse=np.sqrt(mean_squared_error(np.array(actualAvg10), np.array(predictedAvg10)))\n",
    "        r_squared=rsquared(np.array(actualAvg10),np.array(predictedAvg10))\n",
    "        print(\"RMSE and 1-rsquared\", rmse,1-r_squared)\n",
    "        return rmse,r_squared\n",
    "        #r_squared=rsquared(actual.reshape(actual.shape[0]), predicted.reshape(predicted.shape[0]))\n",
    "        #return rmse\n",
    "    \n",
    "def train_predict(model,trainingData,found):\n",
    "        cnt = 0\n",
    "        for column in data.columns:\n",
    "            predictions = list()\n",
    "            testData = np.array(shiftData(data[column][:trainingDataSize+3], lag))\n",
    "            correction = testData[:, -1]\n",
    "            if nDiff > 0:\n",
    "                    testData = np.array(difference(testData))\n",
    "            testX, testY = testData[:, :-1], testData[:, -1]\n",
    "            for i in range(testX.shape[0]):\n",
    "                predictedVal = predict(model, testX[i], lag)\n",
    "                if nDiff > 0:\n",
    "                    predictedVal = predictedVal + correction[i]\n",
    "                    testY[i] = testY[i] + correction[i]\n",
    "                    predictions.append(predictedVal)\n",
    "            t_error,t_rsq = measureRmse(testY, predictions, dataAvg[cnt], dataStd[cnt], column)\n",
    "            cnt = cnt + 1\n",
    "        print(found)\n",
    "        if found==1:\n",
    "            np.savetxt(\"/home/tonystark/shruti_work/genetic-algorithm-master/genetic-algorithm-master/GAwithbatchsize/a_noshuffle_nodrop/\"+str(modelbestName)+\"_training_result\", predictions)\n",
    "        return t_error,t_rsq\n",
    "\n",
    "def test(model, data, config, testDataFirstPredictionIndex,found):\n",
    "        cnt = 0\n",
    "        totalError = 0\n",
    "        lag = config[0]\n",
    "        testDataStartingIndex = testDataFirstPredictionIndex - lag\n",
    "        for column in data.columns:\n",
    "                predictions = list()\n",
    "                testData = np.array(shiftData(data[column][testDataStartingIndex-1:], lag))\n",
    "                correction = testData[:, -1]\n",
    "                if nDiff > 0:\n",
    "                        testData = np.array(difference(testData))\n",
    "                testX, testY = testData[:, :-1], testData[:, -1]\n",
    "                for i in range(testX.shape[0]):\n",
    "                        predictedVal = predict(model, testX[i], lag)\n",
    "                        if nDiff > 0:\n",
    "                                predictedVal = predictedVal + correction[i]\n",
    "                                testY[i] = testY[i] + correction[i]\n",
    "                        predictions.append(predictedVal)\n",
    "                error,rsq = measureRmse(testY, predictions, dataAvg[cnt], dataStd[cnt], column)\n",
    "                totalError += error\n",
    "                cnt = cnt + 1\n",
    "        if found==1:\n",
    "            np.savetxt(\"/home/tonystark/shruti_work/genetic-algorithm-master/genetic-algorithm-master/GAwithbatchsize/a_noshuffle_nodrop/\"+str(modelbestName)+\"_test_result\", predictions)\n",
    "        return totalError,rsq\n",
    "\n",
    "def executeModel(data, config, numPoints,found):\n",
    "    f=open(\"/home/tonystark/shruti_work/genetic-algorithm-master/genetic-algorithm-master/GAwithbatchsize/a_noshuffle_nodrop/result_1a.csv\",'a')\n",
    "    writer=csv.writer(f)\n",
    "    trainingData = prepareDataset(data, lag, numPoints)\n",
    "    bestError=30\n",
    "    for j in range(30):\n",
    "        model,train_loss = train(trainingData, config)\n",
    "        t_error,t_rsq=train_predict(model,trainingData,found)\n",
    "        error,rsq = test(model, data, config, numPoints,found)\n",
    "        #print(error)\n",
    "        modelName=\"Model_1a_\"+str(j)+\"_\"+str(error)\n",
    "        model.save(\"/home/tonystark/shruti_work/genetic-algorithm-master/genetic-algorithm-master/GAwithbatchsize/a_noshuffle_nodrop/\"+\n",
    "modelName)\n",
    "        writer.writerow([modelName,t_error,t_rsq,error,rsq])\n",
    "        if error < bestError:\n",
    "            bestError = error\n",
    "            #bestmodelName=\"best_model\"\n",
    "            model.save(\"/home/tonystark/shruti_work/genetic-algorithm-master/genetic-algorithm-master/GAwithbatchsize/a_noshuffle_nodrop/\"+\n",
    "modelbestName)\n",
    "    return bestError\n",
    "\n",
    "found=0\n",
    "lag = 2\n",
    "trainingDataSize = 1306\n",
    "config = [lag, 8, 8, 20]\n",
    "trainingData = prepareDataset(data, lag,trainingDataSize)\n",
    "print(executeModel(data, config, trainingDataSize,found))\n",
    "\n",
    "model = load_model(\"/home/tonystark/shruti_work/genetic-algorithm-master/genetic-algorithm-master/GAwithbatchsize/a_noshuffle_nodrop/\"+modelbestName)\n",
    "found=1\n",
    "test(model, data, config, trainingDataSize,found)\n",
    "train_predict(model,trainingData,found)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
